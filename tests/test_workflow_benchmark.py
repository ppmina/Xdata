"""
å·¥ä½œæµç¨‹åŸºå‡†æµ‹è¯•

æµ‹è¯•å››ä¸ªç¯èŠ‚çš„æ€§èƒ½ã€å¯é æ€§å’Œè¾¹ç•Œæƒ…å†µ
"""

import pytest
import os
import time
import tempfile
import threading
from pathlib import Path
from typing import Tuple, Any
from datetime import datetime, timedelta

from cryptoservice.models.universe import (
    UniverseDefinition,
    UniverseConfig,
    UniverseSnapshot,
)
from dotenv import load_dotenv

load_dotenv()


class WorkflowBenchmark:
    """å·¥ä½œæµç¨‹åŸºå‡†æµ‹è¯•ç±»"""

    def __init__(self):
        self.api_key = os.getenv("BINANCE_API_KEY")
        self.api_secret = os.getenv("BINANCE_API_SECRET")

    def time_function(self, func, *args, **kwargs) -> Tuple[float, Any]:
        """è®¡æ—¶å‡½æ•°æ‰§è¡Œ"""
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        return end_time - start_time, result


@pytest.mark.benchmark
def test_define_universe_performance():
    """æµ‹è¯•å®šä¹‰Universeçš„æ€§èƒ½"""
    from demo.universe_demo import define_universe

    benchmark = WorkflowBenchmark()

    if not benchmark.api_key or not benchmark.api_secret:
        pytest.skip("éœ€è¦è®¾ç½® BINANCE_API_KEY å’Œ BINANCE_API_SECRET ç¯å¢ƒå˜é‡")

    with tempfile.TemporaryDirectory() as temp_dir:
        universe_file = Path(temp_dir) / "benchmark_universe.json"

        try:
            # æµ‹è¯•ä¸åŒæ—¶é—´èŒƒå›´çš„æ€§èƒ½
            test_cases = [
                ("2024-10-01", "2024-10-07", "1å‘¨æ•°æ®"),
                ("2024-10-01", "2024-10-15", "2å‘¨æ•°æ®"),
                ("2024-10-01", "2024-10-31", "1ä¸ªæœˆæ•°æ®"),
            ]

            results = []

            for start_date, end_date, description in test_cases:
                print(f"\nğŸ• æµ‹è¯• {description}: {start_date} åˆ° {end_date}")

                elapsed_time, universe_def = benchmark.time_function(
                    define_universe,
                    api_key=benchmark.api_key,
                    api_secret=benchmark.api_secret,
                    start_date=start_date,
                    end_date=end_date,
                    output_path=str(universe_file),
                    data_path=temp_dir,
                )

                results.append(
                    {
                        "description": description,
                        "time_range": f"{start_date} åˆ° {end_date}",
                        "elapsed_time": elapsed_time,
                        "snapshots_count": len(universe_def.snapshots),
                        "top_k": universe_def.config.top_k,
                    }
                )

                print(f"   â±ï¸  è€—æ—¶: {elapsed_time:.2f}ç§’")
                print(f"   ğŸ“Š å¿«ç…§æ•°é‡: {len(universe_def.snapshots)}")

                # æ€§èƒ½æ–­è¨€
                assert elapsed_time < 180  # ä¸åº”è¶…è¿‡3åˆ†é’Ÿ
                assert isinstance(universe_def, UniverseDefinition)

            # è¾“å‡ºåŸºå‡†æŠ¥å‘Š
            print(f"\n{'='*60}")
            print("ğŸ¯ å®šä¹‰Universeæ€§èƒ½åŸºå‡†æŠ¥å‘Š")
            print(f"{'='*60}")
            for result in results:
                print(f"ğŸ“‹ {result['description']}")
                print(f"   æ—¶é—´èŒƒå›´: {result['time_range']}")
                print(f"   è€—æ—¶: {result['elapsed_time']:.2f}ç§’")
                print(f"   å¿«ç…§æ•°é‡: {result['snapshots_count']}")
                print(
                    f"   å¹³å‡æ¯ä¸ªå¿«ç…§: {result['elapsed_time']/max(1, result['snapshots_count']):.2f}ç§’"
                )
                print()

        except Exception as e:
            error_msg = str(e).lower()
            if any(keyword in error_msg for keyword in ["api", "network", "timeout", "connection"]):
                pytest.skip(f"APIè®¿é—®é—®é¢˜ï¼Œè·³è¿‡æµ‹è¯•: {e}")
            else:
                raise


@pytest.mark.benchmark
def test_load_universe_performance():
    """æµ‹è¯•åŠ è½½Universeçš„æ€§èƒ½"""
    from demo.universe_demo import load_universe

    benchmark = WorkflowBenchmark()

    # åˆ›å»ºä¸åŒå¤§å°çš„æµ‹è¯•æ•°æ®
    test_cases = [
        (10, 5, "å°å‹universe (10ä¸ªå¿«ç…§, 5ä¸ªäº¤æ˜“å¯¹)"),
        (50, 20, "ä¸­å‹universe (50ä¸ªå¿«ç…§, 20ä¸ªäº¤æ˜“å¯¹)"),
        (100, 50, "å¤§å‹universe (100ä¸ªå¿«ç…§, 50ä¸ªäº¤æ˜“å¯¹)"),
    ]

    with tempfile.TemporaryDirectory() as temp_dir:
        results = []

        for snapshot_count, symbol_count, description in test_cases:
            print(f"\nğŸ• æµ‹è¯• {description}")

            # åˆ›å»ºæµ‹è¯•æ•°æ®
            config = UniverseConfig(
                start_date="2024-01-01",
                end_date="2024-12-31",
                t1_months=1,
                t2_months=1,
                t3_months=3,
                top_k=symbol_count,
            )

            snapshots = []
            for i in range(snapshot_count):
                date = datetime(2024, 1, 1) + timedelta(days=i * 7)
                symbols = [f"SYMBOL{j}USDT" for j in range(symbol_count)]
                amounts = {symbol: float(1000000 + j * 10000) for j, symbol in enumerate(symbols)}

                snapshot = UniverseSnapshot(
                    effective_date=date.strftime("%Y-%m-%d"),
                    period_start_date=(date - timedelta(days=7)).strftime("%Y-%m-%d"),
                    period_end_date=date.strftime("%Y-%m-%d"),
                    symbols=symbols,
                    mean_daily_amounts=amounts,
                )
                snapshots.append(snapshot)

            universe_def = UniverseDefinition(
                config=config,
                snapshots=snapshots,
                creation_time=datetime.now(),
                description=description,
            )

            universe_file = Path(temp_dir) / f"test_universe_{snapshot_count}_{symbol_count}.json"
            universe_def.save_to_file(universe_file)

            # æµ‹è¯•åŠ è½½æ€§èƒ½
            elapsed_time, loaded_universe = benchmark.time_function(
                load_universe, str(universe_file)
            )

            results.append(
                {
                    "description": description,
                    "snapshot_count": snapshot_count,
                    "symbol_count": symbol_count,
                    "elapsed_time": elapsed_time,
                    "file_size": universe_file.stat().st_size / 1024,  # KB
                }
            )

            print(f"   â±ï¸  åŠ è½½è€—æ—¶: {elapsed_time:.4f}ç§’")
            print(f"   ğŸ“ æ–‡ä»¶å¤§å°: {universe_file.stat().st_size / 1024:.2f} KB")

            # æ€§èƒ½æ–­è¨€
            assert elapsed_time < 5.0  # åŠ è½½ä¸åº”è¶…è¿‡5ç§’
            assert len(loaded_universe.snapshots) == snapshot_count

        # è¾“å‡ºåŸºå‡†æŠ¥å‘Š
        print(f"\n{'='*60}")
        print("ğŸ¯ åŠ è½½Universeæ€§èƒ½åŸºå‡†æŠ¥å‘Š")
        print(f"{'='*60}")
        for result in results:
            print(f"ğŸ“‹ {result['description']}")
            print(f"   å¿«ç…§æ•°é‡: {result['snapshot_count']}")
            print(f"   äº¤æ˜“å¯¹æ•°é‡: {result['symbol_count']}")
            print(f"   åŠ è½½è€—æ—¶: {result['elapsed_time']:.4f}ç§’")
            print(f"   æ–‡ä»¶å¤§å°: {result['file_size']:.2f} KB")
            print(f"   åŠ è½½é€Ÿç‡: {result['file_size']/result['elapsed_time']:.2f} KB/ç§’")
            print()


@pytest.mark.benchmark
def test_export_data_performance():
    """æµ‹è¯•å¯¼å‡ºæ•°æ®çš„æ€§èƒ½"""
    from demo.universe_demo import export_data

    benchmark = WorkflowBenchmark()

    # æµ‹è¯•ä¸åŒå¯¼å‡ºæ ¼å¼çš„æ€§èƒ½
    export_formats = ["npy", "csv"]

    with tempfile.TemporaryDirectory() as temp_dir:
        # åˆ›å»ºæµ‹è¯•universe
        config = UniverseConfig(
            start_date="2024-01-01",
            end_date="2024-01-31",
            t1_months=1,
            t2_months=1,
            t3_months=3,
            top_k=20,
        )

        snapshots = []
        for i in range(20):  # 20ä¸ªå¿«ç…§
            date = datetime(2024, 1, 1) + timedelta(days=i)
            symbols = [f"SYMBOL{j}USDT" for j in range(20)]
            amounts = {symbol: float(1000000 + j * 10000) for j, symbol in enumerate(symbols)}

            snapshot = UniverseSnapshot(
                effective_date=date.strftime("%Y-%m-%d"),
                period_start_date=(date - timedelta(days=1)).strftime("%Y-%m-%d"),
                period_end_date=date.strftime("%Y-%m-%d"),
                symbols=symbols,
                mean_daily_amounts=amounts,
            )
            snapshots.append(snapshot)

        universe_def = UniverseDefinition(
            config=config,
            snapshots=snapshots,
            creation_time=datetime.now(),
            description="Export performance test",
        )

        universe_file = Path(temp_dir) / "export_test_universe.json"
        universe_def.save_to_file(universe_file)

        results = []

        for export_format in export_formats:
            print(f"\nğŸ• æµ‹è¯•å¯¼å‡ºæ ¼å¼: {export_format}")

            data_path = Path(temp_dir) / f"data_{export_format}"
            data_path.mkdir(exist_ok=True)

            elapsed_time, _ = benchmark.time_function(
                export_data,
                universe_file=str(universe_file),
                data_path=str(data_path),
                export_format=export_format,
                features=[
                    "open_price",
                    "close_price",
                    "high_price",
                    "low_price",
                    "volume",
                ],
            )

            export_path = data_path / "exports" / export_format

            results.append(
                {
                    "format": export_format,
                    "elapsed_time": elapsed_time,
                    "path_exists": export_path.exists(),
                }
            )

            print(f"   â±ï¸  å¯¼å‡ºè€—æ—¶: {elapsed_time:.4f}ç§’")
            print(f"   ğŸ“ å¯¼å‡ºè·¯å¾„: {export_path}")
            print(f"   âœ… è·¯å¾„å­˜åœ¨: {export_path.exists()}")

            # æ€§èƒ½æ–­è¨€
            assert elapsed_time < 10.0  # å¯¼å‡ºä¸åº”è¶…è¿‡10ç§’
            assert export_path.exists()

        # è¾“å‡ºåŸºå‡†æŠ¥å‘Š
        print(f"\n{'='*60}")
        print("ğŸ¯ å¯¼å‡ºæ•°æ®æ€§èƒ½åŸºå‡†æŠ¥å‘Š")
        print(f"{'='*60}")
        for result in results:
            print(f"ğŸ“‹ æ ¼å¼: {result['format']}")
            print(f"   å¯¼å‡ºè€—æ—¶: {result['elapsed_time']:.4f}ç§’")
            print(f"   æˆåŠŸå¯¼å‡º: {result['path_exists']}")
            print()


@pytest.mark.benchmark
def test_concurrent_load_performance():
    """æµ‹è¯•å¹¶å‘åŠ è½½æ€§èƒ½"""
    from demo.universe_demo import load_universe
    import concurrent.futures

    benchmark = WorkflowBenchmark()

    with tempfile.TemporaryDirectory() as temp_dir:
        # åˆ›å»ºæµ‹è¯•universeæ–‡ä»¶
        config = UniverseConfig(
            start_date="2024-01-01",
            end_date="2024-01-31",
            t1_months=1,
            t2_months=1,
            t3_months=3,
            top_k=10,
        )

        snapshot = UniverseSnapshot(
            effective_date="2024-01-31",
            period_start_date="2024-01-01",
            period_end_date="2024-01-31",
            symbols=[f"SYMBOL{i}USDT" for i in range(10)],
            mean_daily_amounts={f"SYMBOL{i}USDT": float(1000000 + i * 10000) for i in range(10)},
        )

        universe_def = UniverseDefinition(
            config=config,
            snapshots=[snapshot],
            creation_time=datetime.now(),
            description="Concurrent test",
        )

        universe_file = Path(temp_dir) / "concurrent_test_universe.json"
        universe_def.save_to_file(universe_file)

        def load_universe_task():
            """å•ä¸ªåŠ è½½ä»»åŠ¡"""
            start_time = time.time()
            loaded_universe = load_universe(str(universe_file))
            end_time = time.time()
            return {
                "thread_id": threading.current_thread().ident,
                "elapsed_time": end_time - start_time,
                "success": len(loaded_universe.snapshots) > 0,
            }

        # æµ‹è¯•ä¸åŒå¹¶å‘çº§åˆ«
        concurrent_levels = [1, 2, 5, 10]

        for level in concurrent_levels:
            print(f"\nğŸ• æµ‹è¯•å¹¶å‘çº§åˆ«: {level}")

            start_time = time.time()

            with concurrent.futures.ThreadPoolExecutor(max_workers=level) as executor:
                futures = [executor.submit(load_universe_task) for _ in range(level)]
                results = [future.result() for future in concurrent.futures.as_completed(futures)]

            total_time = time.time() - start_time

            success_count = sum(1 for r in results if r["success"])
            avg_task_time = sum(r["elapsed_time"] for r in results) / len(results)

            print(f"   â±ï¸  æ€»è€—æ—¶: {total_time:.4f}ç§’")
            print(f"   ğŸ“Š æˆåŠŸä»»åŠ¡: {success_count}/{level}")
            print(f"   ğŸ“ˆ å¹³å‡ä»»åŠ¡æ—¶é—´: {avg_task_time:.4f}ç§’")
            print(f"   ğŸš€ ååé‡: {level/total_time:.2f} ä»»åŠ¡/ç§’")

            # æ€§èƒ½æ–­è¨€
            assert success_count == level  # æ‰€æœ‰ä»»åŠ¡éƒ½åº”æˆåŠŸ
            assert total_time < 30.0  # æ€»æ—¶é—´ä¸åº”è¶…è¿‡30ç§’


@pytest.mark.benchmark
def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    import psutil
    import gc
    from demo.universe_demo import load_universe

    def get_memory_usage():
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ (MB)"""
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024

    with tempfile.TemporaryDirectory() as temp_dir:
        # åˆ›å»ºå¤§å‹æµ‹è¯•æ•°æ®
        config = UniverseConfig(
            start_date="2024-01-01",
            end_date="2024-12-31",
            t1_months=1,
            t2_months=1,
            t3_months=3,
            top_k=100,
        )

        # åˆ›å»º365ä¸ªå¿«ç…§ï¼ˆæ¯å¤©ä¸€ä¸ªï¼‰
        snapshots = []
        for i in range(365):
            date = datetime(2024, 1, 1) + timedelta(days=i)
            symbols = [f"SYMBOL{j}USDT" for j in range(100)]
            amounts = {symbol: float(1000000 + j * 10000) for j, symbol in enumerate(symbols)}

            snapshot = UniverseSnapshot(
                effective_date=date.strftime("%Y-%m-%d"),
                period_start_date=(date - timedelta(days=1)).strftime("%Y-%m-%d"),
                period_end_date=date.strftime("%Y-%m-%d"),
                symbols=symbols,
                mean_daily_amounts=amounts,
            )
            snapshots.append(snapshot)

        universe_def = UniverseDefinition(
            config=config,
            snapshots=snapshots,
            creation_time=datetime.now(),
            description="Memory test",
        )

        universe_file = Path(temp_dir) / "memory_test_universe.json"
        universe_def.save_to_file(universe_file)

        # æµ‹è¯•å†…å­˜ä½¿ç”¨
        initial_memory = get_memory_usage()
        print(f"ğŸ“Š åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.2f} MB")

        # åŠ è½½universe
        loaded_universe = load_universe(str(universe_file))
        after_load_memory = get_memory_usage()
        memory_increase = after_load_memory - initial_memory

        print(f"ğŸ“ˆ åŠ è½½åå†…å­˜ä½¿ç”¨: {after_load_memory:.2f} MB")
        print(f"ğŸ“Š å†…å­˜å¢é•¿: {memory_increase:.2f} MB")

        # åˆ é™¤å¼•ç”¨å¹¶åƒåœ¾å›æ”¶
        del loaded_universe
        gc.collect()
        after_gc_memory = get_memory_usage()
        memory_recovered = after_load_memory - after_gc_memory

        print(f"ğŸ§¹ åƒåœ¾å›æ”¶åå†…å­˜: {after_gc_memory:.2f} MB")
        print(f"â™»ï¸  å›æ”¶å†…å­˜: {memory_recovered:.2f} MB")

        # å†…å­˜æ–­è¨€
        assert memory_increase < 500  # å†…å­˜å¢é•¿ä¸åº”è¶…è¿‡500MB
        assert memory_recovered > memory_increase * 0.5  # è‡³å°‘å›æ”¶50%çš„å†…å­˜


if __name__ == "__main__":
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    pytest.main([__file__, "-v", "-m", "benchmark"])
