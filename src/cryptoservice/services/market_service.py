"""å¸‚åœºæ•°æ®æœåŠ¡ã€‚

ä¸“æ³¨äºæ ¸å¿ƒAPIåŠŸèƒ½ï¼Œä½¿ç”¨ç»„åˆæ¨¡å¼æ•´åˆå„ä¸ªä¸“ä¸šæ¨¡å—ã€‚
"""

import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Optional

from cryptoservice.client import BinanceClientFactory
from cryptoservice.utils import DataConverter
from cryptoservice.storage import AsyncMarketDB
from cryptoservice.exceptions import InvalidSymbolError, MarketDataFetchError
from cryptoservice.models import (
    DailyMarketTicker,
    Freq,
    HistoricalKlinesType,
    KlineMarketTicker,
    SortBy,
    SymbolTicker,
    UniverseDefinition,
    IntegrityReport,
    FundingRate,
    OpenInterest,
    LongShortRatio,
)
from cryptoservice.config import settings, RetryConfig

# å¯¼å…¥æ–°çš„æ¨¡å—
from .downloaders import KlineDownloader, MetricsDownloader, VisionDownloader
from .processors import DataValidator, UniverseManager, CategoryManager

logger = logging.getLogger(__name__)


class MarketDataService:
    """å¸‚åœºæ•°æ®æœåŠ¡å®ç°ç±»ï¼ˆé‡æ„ç‰ˆï¼‰"""

    def __init__(self, api_key: str, api_secret: str) -> None:
        """åˆå§‹åŒ–å¸‚åœºæ•°æ®æœåŠ¡"""
        self.client = BinanceClientFactory.create_client(api_key, api_secret)
        self.converter = DataConverter()
        self.db: AsyncMarketDB | None = None

        # åˆå§‹åŒ–å„ç§ä¸“ä¸šæ¨¡å—
        self.kline_downloader = KlineDownloader(self.client)
        self.metrics_downloader = MetricsDownloader(self.client)
        self.vision_downloader = VisionDownloader(self.client)
        self.data_validator = DataValidator()
        self.universe_manager = UniverseManager(self)
        self.category_manager = CategoryManager()

    # ==================== åŸºç¡€å¸‚åœºæ•°æ®API ====================

    def get_symbol_ticker(self, symbol: str | None = None) -> SymbolTicker | list[SymbolTicker]:
        """è·å–å•ä¸ªæˆ–æ‰€æœ‰äº¤æ˜“å¯¹çš„è¡Œæƒ…æ•°æ®"""
        try:
            ticker = self.client.get_symbol_ticker(symbol=symbol)
            if not ticker:
                raise InvalidSymbolError(f"Invalid symbol: {symbol}")

            if isinstance(ticker, list):
                return [SymbolTicker.from_binance_ticker(t) for t in ticker]
            return SymbolTicker.from_binance_ticker(ticker)

        except Exception as e:
            logger.error(f"Error fetching ticker for {symbol}: {e}")
            raise MarketDataFetchError(f"Failed to fetch ticker: {e}") from e

    def get_perpetual_symbols(self, only_trading: bool = True, quote_asset: str = "USDT") -> list[str]:
        """è·å–å½“å‰å¸‚åœºä¸Šæ‰€æœ‰æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹"""
        try:
            logger.info(f"è·å–å½“å‰æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹åˆ—è¡¨ï¼ˆç­›é€‰æ¡ä»¶ï¼š{quote_asset}ç»“å°¾ï¼‰")
            futures_info = self.client.futures_exchange_info()
            perpetual_symbols = [
                symbol["symbol"]
                for symbol in futures_info["symbols"]
                if symbol["contractType"] == "PERPETUAL"
                and (not only_trading or symbol["status"] == "TRADING")
                and symbol["symbol"].endswith(quote_asset)
            ]

            logger.info(f"æ‰¾åˆ° {len(perpetual_symbols)} ä¸ª{quote_asset}æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹")
            return perpetual_symbols

        except Exception as e:
            logger.error(f"è·å–æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹å¤±è´¥: {e}")
            raise MarketDataFetchError(f"è·å–æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹å¤±è´¥: {e}") from e

    def get_top_coins(
        self,
        limit: int = settings.DEFAULT_LIMIT,
        sort_by: SortBy = SortBy.QUOTE_VOLUME,
        quote_asset: str | None = None,
    ) -> list[DailyMarketTicker]:
        """è·å–å‰Nä¸ªäº¤æ˜“å¯¹"""
        try:
            tickers = self.client.get_ticker()
            market_tickers = [DailyMarketTicker.from_binance_ticker(t) for t in tickers]

            if quote_asset:
                market_tickers = [t for t in market_tickers if t.symbol.endswith(quote_asset)]

            return sorted(
                market_tickers,
                key=lambda x: getattr(x, sort_by.value),
                reverse=True,
            )[:limit]

        except Exception as e:
            logger.error(f"Error getting top coins: {e}")
            raise MarketDataFetchError(f"Failed to get top coins: {e}") from e

    def get_market_summary(self, interval: Freq = Freq.d1) -> dict[str, Any]:
        """è·å–å¸‚åœºæ¦‚è§ˆ"""
        try:
            summary: dict[str, Any] = {"snapshot_time": datetime.now(), "data": {}}
            tickers_result = self.get_symbol_ticker()
            if isinstance(tickers_result, list):
                tickers = [ticker.to_dict() for ticker in tickers_result]
            else:
                tickers = [tickers_result.to_dict()]
            summary["data"] = tickers

            return summary

        except Exception as e:
            logger.error(f"Error getting market summary: {e}")
            raise MarketDataFetchError(f"Failed to get market summary: {e}") from e

    def get_historical_klines(
        self,
        symbol: str,
        start_time: str | datetime,
        end_time: str | datetime | None = None,
        interval: Freq = Freq.h1,
        klines_type: HistoricalKlinesType = HistoricalKlinesType.SPOT,
    ) -> list[KlineMarketTicker]:
        """è·å–å†å²è¡Œæƒ…æ•°æ®"""
        try:
            # å¤„ç†æ—¶é—´æ ¼å¼
            if isinstance(start_time, str):
                start_time = datetime.fromisoformat(start_time)
            if end_time is None:
                end_time = datetime.now()
            elif isinstance(end_time, str):
                end_time = datetime.fromisoformat(end_time)

            # è½¬æ¢ä¸ºæ—¶é—´æˆ³
            start_ts = self._date_to_timestamp_start(start_time.strftime("%Y-%m-%d"))
            end_ts = self._date_to_timestamp_end(end_time.strftime("%Y-%m-%d"))

            logger.info(f"è·å– {symbol} çš„å†å²æ•°æ® ({interval.value})")

            # æ ¹æ®klines_typeé€‰æ‹©API
            if klines_type == HistoricalKlinesType.FUTURES:
                klines = self.client.futures_klines(
                    symbol=symbol,
                    interval=interval.value,
                    startTime=start_ts,
                    endTime=end_ts,
                    limit=1500,
                )
            else:  # SPOT
                klines = self.client.get_klines(
                    symbol=symbol,
                    interval=interval.value,
                    startTime=start_ts,
                    endTime=end_ts,
                    limit=1500,
                )

            data = list(klines)
            if not data:
                logger.warning(f"æœªæ‰¾åˆ°äº¤æ˜“å¯¹ {symbol} åœ¨æŒ‡å®šæ—¶é—´æ®µå†…çš„æ•°æ®")
                return []

            # è½¬æ¢ä¸ºKlineMarketTickerå¯¹è±¡
            from decimal import Decimal

            return [
                KlineMarketTicker(
                    symbol=symbol,
                    last_price=Decimal(str(kline[4])),  # æ”¶ç›˜ä»·ä½œä¸ºæœ€æ–°ä»·æ ¼
                    open_price=Decimal(str(kline[1])),
                    high_price=Decimal(str(kline[2])),
                    low_price=Decimal(str(kline[3])),
                    volume=Decimal(str(kline[5])),
                    close_time=kline[6],
                )
                for kline in data
            ]

        except Exception as e:
            logger.error(f"Error getting historical data for {symbol}: {e}")
            raise MarketDataFetchError(f"Failed to get historical data: {e}") from e

    # ==================== å¸‚åœºæŒ‡æ ‡API ====================

    def get_funding_rate(
        self,
        symbol: str,
        start_time: str | datetime | None = None,
        end_time: str | datetime | None = None,
        limit: int = 100,
    ) -> list[FundingRate]:
        """è·å–æ°¸ç»­åˆçº¦èµ„é‡‘è´¹ç‡å†å²"""
        # è½¬æ¢æ—¶é—´æ ¼å¼
        start_time_str = self._convert_time_to_string(start_time) if start_time else ""
        end_time_str = self._convert_time_to_string(end_time) if end_time else ""

        return self.metrics_downloader.download_funding_rate(
            symbol=symbol,
            start_time=start_time_str,
            end_time=end_time_str,
            limit=limit,
        )

    def get_open_interest(
        self,
        symbol: str,
        period: str = "5m",
        start_time: str | datetime | None = None,
        end_time: str | datetime | None = None,
        limit: int = 500,
    ) -> list[OpenInterest]:
        """è·å–æ°¸ç»­åˆçº¦æŒä»“é‡æ•°æ®"""
        # è½¬æ¢æ—¶é—´æ ¼å¼
        start_time_str = self._convert_time_to_string(start_time) if start_time else ""
        end_time_str = self._convert_time_to_string(end_time) if end_time else ""

        return self.metrics_downloader.download_open_interest(
            symbol=symbol,
            period=period,
            start_time=start_time_str,
            end_time=end_time_str,
            limit=limit,
        )

    def get_long_short_ratio(
        self,
        symbol: str,
        period: str = "5m",
        ratio_type: str = "account",
        start_time: str | datetime | None = None,
        end_time: str | datetime | None = None,
        limit: int = 500,
    ) -> list[LongShortRatio]:
        """è·å–å¤šç©ºæ¯”ä¾‹æ•°æ®"""
        # è½¬æ¢æ—¶é—´æ ¼å¼
        start_time_str = self._convert_time_to_string(start_time) if start_time else ""
        end_time_str = self._convert_time_to_string(end_time) if end_time else ""

        return self.metrics_downloader.download_long_short_ratio(
            symbol=symbol,
            period=period,
            ratio_type=ratio_type,
            start_time=start_time_str,
            end_time=end_time_str,
            limit=limit,
        )

    # ==================== æ‰¹é‡æ•°æ®ä¸‹è½½ ====================

    async def get_perpetual_data(
        self,
        symbols: list[str],
        start_time: str,
        db_path: Path | str,
        end_time: str | None = None,
        interval: Freq = Freq.h1,
        max_workers: int = 5,
        max_retries: int = 3,
        progress=None,
        request_delay: float = 0.5,
        retry_config: Optional[RetryConfig] = None,
        enable_integrity_check: bool = True,
    ) -> IntegrityReport:
        """è·å–æ°¸ç»­åˆçº¦æ•°æ®å¹¶å­˜å‚¨"""
        # éªŒè¯å¹¶å‡†å¤‡æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        db_file_path = self._validate_and_prepare_path(db_path, is_file=True)
        end_time = end_time or datetime.now().strftime("%Y-%m-%d")

        # ä½¿ç”¨Kçº¿ä¸‹è½½å™¨
        return await self.kline_downloader.download_multiple_symbols(
            symbols=symbols,
            start_time=start_time,
            end_time=end_time,
            interval=interval,
            db_path=db_file_path,
            max_workers=max_workers,
            retry_config=retry_config or RetryConfig(max_retries=max_retries),
        )

    async def download_universe_data(
        self,
        universe_file: Path | str,
        db_path: Path | str,
        data_path: Path | str | None = None,
        interval: Freq = Freq.m1,
        max_workers: int = 4,
        max_retries: int = 3,
        include_buffer_days: int = 7,
        retry_config: RetryConfig | None = None,
        request_delay: float = 0.5,
        download_market_metrics: bool = True,
        metrics_interval: Freq = Freq.m5,
        long_short_ratio_period: Freq = Freq.m5,
        long_short_ratio_types: list[str] | None = None,
        use_binance_vision: bool = False,
    ) -> None:
        """æŒ‰å‘¨æœŸåˆ†åˆ«ä¸‹è½½universeæ•°æ®"""
        try:
            # éªŒè¯è·¯å¾„
            universe_file_obj = self._validate_and_prepare_path(universe_file, is_file=True)
            db_file_path = self._validate_and_prepare_path(db_path, is_file=True)

            # æ£€æŸ¥universeæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not universe_file_obj.exists():
                raise FileNotFoundError(f"Universeæ–‡ä»¶ä¸å­˜åœ¨: {universe_file_obj}")

            # åŠ è½½universeå®šä¹‰
            universe_def = UniverseDefinition.load_from_file(universe_file_obj)

            # è®¾ç½®å¤šç©ºæ¯”ä¾‹ç±»å‹é»˜è®¤å€¼
            if long_short_ratio_types is None:
                long_short_ratio_types = ["account", "position"]

            logger.info("ğŸ“Š æŒ‰å‘¨æœŸä¸‹è½½æ•°æ®:")
            logger.info(f"   - æ€»å¿«ç…§æ•°: {len(universe_def.snapshots)}")
            logger.info(f"   - æ•°æ®é¢‘ç‡: {interval.value}")
            logger.info(f"   - å¹¶å‘çº¿ç¨‹: {max_workers}")
            logger.info(f"   - è¯·æ±‚é—´éš”: {request_delay}ç§’")
            logger.info(f"   - æ•°æ®åº“è·¯å¾„: {db_file_path}")
            logger.info(f"   - ä¸‹è½½å¸‚åœºæŒ‡æ ‡: {download_market_metrics}")

            # ä¸ºæ¯ä¸ªå‘¨æœŸå•ç‹¬ä¸‹è½½æ•°æ®
            for i, snapshot in enumerate(universe_def.snapshots):
                logger.info(f"ğŸ“… å¤„ç†å¿«ç…§ {i + 1}/{len(universe_def.snapshots)}: {snapshot.effective_date}")

                # ä¸‹è½½Kçº¿æ•°æ®
                await self.get_perpetual_data(
                    symbols=snapshot.symbols,
                    start_time=snapshot.start_date,
                    end_time=snapshot.end_date,
                    db_path=db_file_path,
                    interval=interval,
                    max_workers=max_workers,
                    max_retries=max_retries,
                    retry_config=retry_config,
                    enable_integrity_check=True,
                    request_delay=request_delay,
                )

                # ä¸‹è½½å¸‚åœºæŒ‡æ ‡æ•°æ®
                if download_market_metrics:
                    logger.info("   ğŸ“ˆ å¼€å§‹ä¸‹è½½å¸‚åœºæŒ‡æ ‡æ•°æ®...")
                    await self._download_market_metrics_for_snapshot(
                        snapshot=snapshot,
                        db_path=db_file_path,
                        interval=metrics_interval,
                        period=long_short_ratio_period,
                        long_short_ratio_types=long_short_ratio_types,
                        request_delay=request_delay,
                        use_binance_vision=use_binance_vision,
                    )

                logger.info(f"   âœ… å¿«ç…§ {snapshot.effective_date} ä¸‹è½½å®Œæˆ")

            logger.info("ğŸ‰ æ‰€æœ‰universeæ•°æ®ä¸‹è½½å®Œæˆ!")
            logger.info(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: {db_file_path}")

        except Exception as e:
            logger.error(f"æŒ‰å‘¨æœŸä¸‹è½½universeæ•°æ®å¤±è´¥: {e}")
            raise MarketDataFetchError(f"æŒ‰å‘¨æœŸä¸‹è½½universeæ•°æ®å¤±è´¥: {e}") from e

    # ==================== Universeç®¡ç† ====================

    def define_universe(
        self,
        start_date: str,
        end_date: str,
        t1_months: int,
        t2_months: int,
        t3_months: int,
        output_path: Path | str,
        top_k: int | None = None,
        top_ratio: float | None = None,
        description: str | None = None,
        delay_days: int = 7,
        api_delay_seconds: float = 1.0,
        batch_delay_seconds: float = 3.0,
        batch_size: int = 5,
        quote_asset: str = "USDT",
    ) -> UniverseDefinition:
        """å®šä¹‰universeå¹¶ä¿å­˜åˆ°æ–‡ä»¶"""
        return self.universe_manager.define_universe(
            start_date=start_date,
            end_date=end_date,
            t1_months=t1_months,
            t2_months=t2_months,
            t3_months=t3_months,
            output_path=output_path,
            top_k=top_k,
            top_ratio=top_ratio,
            description=description,
            delay_days=delay_days,
            api_delay_seconds=api_delay_seconds,
            batch_delay_seconds=batch_delay_seconds,
            batch_size=batch_size,
            quote_asset=quote_asset,
        )

    # ==================== åˆ†ç±»ç®¡ç† ====================

    def get_symbol_categories(self) -> dict[str, list[str]]:
        """è·å–å½“å‰æ‰€æœ‰äº¤æ˜“å¯¹çš„åˆ†ç±»ä¿¡æ¯"""
        return self.category_manager.get_symbol_categories()

    def get_all_categories(self) -> list[str]:
        """è·å–æ‰€æœ‰å¯èƒ½çš„åˆ†ç±»æ ‡ç­¾"""
        return self.category_manager.get_all_categories()

    def create_category_matrix(
        self, symbols: list[str], categories: list[str] | None = None
    ) -> tuple[list[str], list[str], list[list[int]]]:
        """åˆ›å»º symbols å’Œ categories çš„å¯¹åº”çŸ©é˜µ"""
        categories_list = categories if categories is not None else []
        return self.category_manager.create_category_matrix(symbols, categories_list)

    def save_category_matrix_csv(
        self,
        output_path: Path | str,
        symbols: list[str],
        date_str: str | None = None,
        categories: list[str] | None = None,
    ) -> None:
        """å°†åˆ†ç±»çŸ©é˜µä¿å­˜ä¸º CSV æ–‡ä»¶"""
        date_str_value = date_str if date_str is not None else ""
        categories_list = categories if categories is not None else []
        self.category_manager.save_category_matrix_csv(
            output_path=output_path,
            symbols=symbols,
            date_str=date_str_value,
            categories=categories_list,
        )

    def download_and_save_categories_for_universe(
        self,
        universe_file: Path | str,
        output_path: Path | str,
        categories: list[str] | None = None,
    ) -> None:
        """ä¸º universe ä¸­çš„æ‰€æœ‰äº¤æ˜“å¯¹ä¸‹è½½å¹¶ä¿å­˜åˆ†ç±»ä¿¡æ¯"""
        categories_list = categories if categories is not None else []
        self.category_manager.download_and_save_categories_for_universe(
            universe_file=universe_file,
            output_path=output_path,
            categories=categories_list,
        )

    # ==================== ç§æœ‰è¾…åŠ©æ–¹æ³• ====================

    async def _download_market_metrics_for_snapshot(
        self,
        snapshot,
        db_path: Path,
        interval: Freq = Freq.m5,
        period: Freq = Freq.m5,
        long_short_ratio_types: list[str] | None = None,
        request_delay: float = 0.5,
        use_binance_vision: bool = False,
    ) -> None:
        """ä¸ºå•ä¸ªå¿«ç…§ä¸‹è½½å¸‚åœºæŒ‡æ ‡æ•°æ®"""
        try:
            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
            if self.db is None:
                self.db = AsyncMarketDB(str(db_path))

            # è®¾ç½®é»˜è®¤å€¼
            if long_short_ratio_types is None:
                long_short_ratio_types = ["account"]

            symbols = snapshot.symbols
            start_time = snapshot.start_date
            end_time = snapshot.end_date

            if use_binance_vision:
                logger.info("      ğŸ“Š ä½¿ç”¨ Binance Vision ä¸‹è½½å¸‚åœºæŒ‡æ ‡æ•°æ®...")
                await self.vision_downloader.download_metrics_batch(
                    symbols=symbols,
                    start_date=start_time,
                    end_date=end_time,
                    db_path=str(db_path),
                    request_delay=request_delay,
                )
            else:
                logger.info("      ğŸ“Š ä½¿ç”¨ API ä¸‹è½½å¸‚åœºæŒ‡æ ‡æ•°æ®...")

                # ä¸‹è½½èµ„é‡‘è´¹ç‡
                await self.metrics_downloader.download_funding_rate_batch(
                    symbols=symbols,
                    start_time=start_time,
                    end_time=end_time,
                    db_path=str(db_path),
                    request_delay=request_delay,
                )

                # ä¸‹è½½æŒä»“é‡
                await self.metrics_downloader.download_open_interest_batch(
                    symbols=symbols,
                    start_time=start_time,
                    end_time=end_time,
                    db_path=str(db_path),
                    interval=interval,
                    request_delay=request_delay,
                )

                # ä¸‹è½½å¤šç©ºæ¯”ä¾‹
                for ratio_type in long_short_ratio_types:
                    logger.info(f"        - ç±»å‹: {ratio_type}")
                    await self.metrics_downloader.download_long_short_ratio_batch(
                        symbols=symbols,
                        start_time=start_time,
                        end_time=end_time,
                        db_path=str(db_path),
                        period=period.value,
                        ratio_type=ratio_type,
                        request_delay=request_delay,
                    )

            logger.info("      âœ… å¸‚åœºæŒ‡æ ‡æ•°æ®ä¸‹è½½å®Œæˆ")

        except Exception as e:
            logger.error(f"ä¸‹è½½å¸‚åœºæŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
            raise MarketDataFetchError(f"ä¸‹è½½å¸‚åœºæŒ‡æ ‡æ•°æ®å¤±è´¥: {e}") from e

    def _validate_and_prepare_path(self, path: Path | str, is_file: bool = False, file_name: str | None = None) -> Path:
        """éªŒè¯å¹¶å‡†å¤‡è·¯å¾„"""
        if not path:
            raise ValueError("è·¯å¾„ä¸èƒ½ä¸ºç©ºï¼Œå¿…é¡»æ‰‹åŠ¨æŒ‡å®š")

        path_obj = Path(path)

        # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„ï¼Œç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
        if is_file:
            if path_obj.is_dir():
                path_obj = path_obj.joinpath(file_name) if file_name else path_obj
            else:
                path_obj.parent.mkdir(parents=True, exist_ok=True)
        else:
            # å¦‚æœæ˜¯ç›®å½•è·¯å¾„ï¼Œç¡®ä¿ç›®å½•å­˜åœ¨
            path_obj.mkdir(parents=True, exist_ok=True)

        return path_obj

    def _date_to_timestamp_start(self, date: str) -> str:
        """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºå½“å¤©å¼€å§‹çš„æ—¶é—´æˆ³"""
        timestamp = int(datetime.strptime(f"{date} 00:00:00", "%Y-%m-%d %H:%M:%S").timestamp() * 1000)
        return str(timestamp)

    def _date_to_timestamp_end(self, date: str) -> str:
        """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºå½“å¤©ç»“æŸçš„æ—¶é—´æˆ³"""
        timestamp = int(datetime.strptime(f"{date} 23:59:59", "%Y-%m-%d %H:%M:%S").timestamp() * 1000)
        return str(timestamp)

    def _convert_time_to_string(self, time_value: str | datetime | None) -> str:
        """å°†æ—¶é—´å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼"""
        if time_value is None:
            return ""
        if isinstance(time_value, str):
            return time_value
        if isinstance(time_value, datetime):
            return time_value.strftime("%Y-%m-%d")
        raise ValueError(f"Unsupported time type: {type(time_value)}")

    def check_symbol_exists_on_date(self, symbol: str, date: str) -> bool:
        """æ£€æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦å­˜åœ¨è¯¥äº¤æ˜“å¯¹"""
        try:
            # å°†æ—¥æœŸè½¬æ¢ä¸ºæ—¶é—´æˆ³èŒƒå›´
            start_time = self._date_to_timestamp_start(date)
            end_time = self._date_to_timestamp_end(date)

            # å°è¯•è·å–è¯¥æ—¶é—´èŒƒå›´å†…çš„Kçº¿æ•°æ®
            klines = self.client.futures_klines(
                symbol=symbol,
                interval="1d",
                startTime=start_time,
                endTime=end_time,
                limit=1,
            )

            # å¦‚æœæœ‰æ•°æ®ï¼Œè¯´æ˜è¯¥æ—¥æœŸå­˜åœ¨è¯¥äº¤æ˜“å¯¹
            return bool(klines and len(klines) > 0)

        except Exception as e:
            logger.debug(f"æ£€æŸ¥äº¤æ˜“å¯¹ {symbol} åœ¨ {date} æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: {e}")
            return False

    # ==================== æ”¯æŒæ—§ç‰ˆæœ¬çš„æ–¹æ³• ====================

    def _fetch_symbol_data(self, *args, **kwargs):
        """æ”¯æŒæ—§ç‰ˆæœ¬çš„æ–¹æ³•ï¼Œå§”æ‰˜ç»™Kçº¿ä¸‹è½½å™¨"""
        return self.kline_downloader.download_single_symbol(*args, **kwargs)

    @property
    def rate_limit_manager(self):
        """æä¾›å‘åå…¼å®¹çš„rate_limit_managerå±æ€§"""
        return self.kline_downloader.rate_limit_manager

    @rate_limit_manager.setter
    def rate_limit_manager(self, value):
        """è®¾ç½®rate_limit_manager"""
        self.kline_downloader.rate_limit_manager = value
        self.metrics_downloader.rate_limit_manager = value
        self.vision_downloader.rate_limit_manager = value
