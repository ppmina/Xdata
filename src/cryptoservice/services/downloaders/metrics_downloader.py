"""å¸‚åœºæŒ‡æ ‡æ•°æ®ä¸‹è½½å™¨ã€‚

ä¸“é—¨å¤„ç†èµ„é‡‘è´¹ç‡ã€æŒä»“é‡ã€å¤šç©ºæ¯”ä¾‹ç­‰å¸‚åœºæŒ‡æ ‡æ•°æ®çš„ä¸‹è½½ã€‚
"""

import logging
import time
from datetime import datetime, timedelta
from typing import List, Optional

from cryptoservice.models import FundingRate, OpenInterest, LongShortRatio, Freq
from cryptoservice.exceptions import MarketDataFetchError
from cryptoservice.storage import AsyncMarketDB
from .base_downloader import BaseDownloader

logger = logging.getLogger(__name__)


class MetricsDownloader(BaseDownloader):
    """å¸‚åœºæŒ‡æ ‡æ•°æ®ä¸‹è½½å™¨"""

    def __init__(self, client, request_delay: float = 0.5):
        super().__init__(client, request_delay)
        self.db: Optional[AsyncMarketDB] = None

    async def download_funding_rate_batch(
        self,
        symbols: List[str],
        start_time: str,
        end_time: str,
        db_path: str,
        request_delay: float = 0.5,
    ) -> None:
        """æ‰¹é‡ä¸‹è½½èµ„é‡‘è´¹ç‡æ•°æ®"""
        try:
            logger.info("ğŸ’° æ‰¹é‡ä¸‹è½½èµ„é‡‘è´¹ç‡æ•°æ®")

            if self.db is None:
                self.db = AsyncMarketDB(db_path)

            all_funding_rates = []
            downloaded_count = 0
            failed_count = 0

            for i, symbol in enumerate(symbols):
                try:
                    logger.debug(f"è·å– {symbol} èµ„é‡‘è´¹ç‡ ({i + 1}/{len(symbols)})")

                    # é¢‘ç‡é™åˆ¶
                    if request_delay > 0:
                        time.sleep(request_delay)

                    funding_rates = self.download_funding_rate(
                        symbol=symbol,
                        start_time=start_time,
                        end_time=end_time,
                        limit=1000,
                    )

                    if funding_rates:
                        all_funding_rates.extend(funding_rates)
                        downloaded_count += 1
                        logger.debug(f"âœ… {symbol}: {len(funding_rates)} æ¡è®°å½•")
                    else:
                        logger.debug(f"âš ï¸ {symbol}: æ— æ•°æ®")

                except Exception as e:
                    failed_count += 1
                    logger.warning(f"âŒ {symbol}: {e}")
                    self._record_failed_download(
                        symbol,
                        str(e),
                        {
                            "data_type": "funding_rate",
                            "start_time": start_time,
                            "end_time": end_time,
                        },
                    )

            # æ‰¹é‡å­˜å‚¨
            if all_funding_rates and self.db:
                await self.db.store_funding_rate(all_funding_rates)
                logger.info(f"âœ… å­˜å‚¨äº† {len(all_funding_rates)} æ¡èµ„é‡‘è´¹ç‡è®°å½•")

            logger.info(f"ğŸ’° èµ„é‡‘è´¹ç‡æ•°æ®ä¸‹è½½å®Œæˆ: æˆåŠŸ {downloaded_count}/{len(symbols)}ï¼Œå¤±è´¥ {failed_count}")

        except Exception as e:
            logger.error(f"æ‰¹é‡ä¸‹è½½èµ„é‡‘è´¹ç‡å¤±è´¥: {e}")
            raise MarketDataFetchError(f"æ‰¹é‡ä¸‹è½½èµ„é‡‘è´¹ç‡å¤±è´¥: {e}") from e

    async def download_open_interest_batch(
        self,
        symbols: List[str],
        start_time: str,
        end_time: str,
        db_path: str,
        interval: Freq = Freq.m5,
        request_delay: float = 0.5,
    ) -> None:
        """æ‰¹é‡ä¸‹è½½æŒä»“é‡æ•°æ®"""
        try:
            logger.info("ğŸ“Š æ‰¹é‡ä¸‹è½½æŒä»“é‡æ•°æ®")

            if self.db is None:
                self.db = AsyncMarketDB(db_path)

            all_open_interests = []
            downloaded_count = 0
            failed_count = 0

            for i, symbol in enumerate(symbols):
                try:
                    logger.debug(f"è·å– {symbol} æŒä»“é‡ ({i + 1}/{len(symbols)})")

                    # é¢‘ç‡é™åˆ¶
                    if request_delay > 0:
                        time.sleep(request_delay)

                    open_interests = self.download_open_interest(
                        symbol=symbol,
                        period=interval.value,
                        start_time=start_time,
                        end_time=end_time,
                        limit=500,
                    )

                    if open_interests:
                        all_open_interests.extend(open_interests)
                        downloaded_count += 1
                        logger.debug(f"âœ… {symbol}: {len(open_interests)} æ¡è®°å½•")
                    else:
                        logger.debug(f"âš ï¸ {symbol}: æ— æ•°æ®")

                except Exception as e:
                    failed_count += 1
                    logger.warning(f"âŒ {symbol}: {e}")
                    self._record_failed_download(
                        symbol,
                        str(e),
                        {
                            "data_type": "open_interest",
                            "start_time": start_time,
                            "end_time": end_time,
                        },
                    )

            # æ‰¹é‡å­˜å‚¨
            if all_open_interests and self.db:
                await self.db.store_open_interest(all_open_interests)
                logger.info(f"âœ… å­˜å‚¨äº† {len(all_open_interests)} æ¡æŒä»“é‡è®°å½•")

            logger.info(f"ğŸ“Š æŒä»“é‡æ•°æ®ä¸‹è½½å®Œæˆ: æˆåŠŸ {downloaded_count}/{len(symbols)}ï¼Œå¤±è´¥ {failed_count}")

        except Exception as e:
            logger.error(f"æ‰¹é‡ä¸‹è½½æŒä»“é‡å¤±è´¥: {e}")
            raise MarketDataFetchError(f"æ‰¹é‡ä¸‹è½½æŒä»“é‡å¤±è´¥: {e}") from e

    async def download_long_short_ratio_batch(
        self,
        symbols: List[str],
        start_time: str,
        end_time: str,
        db_path: str,
        period: str = "5m",
        ratio_type: str = "account",
        request_delay: float = 0.5,
    ) -> None:
        """æ‰¹é‡ä¸‹è½½å¤šç©ºæ¯”ä¾‹æ•°æ®"""
        try:
            logger.info(f"ğŸ“Š æ‰¹é‡ä¸‹è½½å¤šç©ºæ¯”ä¾‹æ•°æ® (ç±»å‹: {ratio_type})")

            if self.db is None:
                self.db = AsyncMarketDB(db_path)

            # æ£€æŸ¥30å¤©é™åˆ¶
            current_time = datetime.now()
            thirty_days_ago = current_time - timedelta(days=30)

            # è§£ææ—¶é—´å­—ç¬¦ä¸²
            try:
                start_dt = datetime.fromisoformat(
                    start_time.replace("Z", "+00:00") if start_time.endswith("Z") else start_time
                )
            except ValueError:
                start_dt = datetime.fromisoformat(start_time)

            # è°ƒæ•´æ—¶é—´èŒƒå›´ä»¥ç¬¦åˆ30å¤©é™åˆ¶
            if start_dt < thirty_days_ago:
                logger.warning("âš ï¸ å¼€å§‹æ—¶é—´è¶…å‡º30å¤©é™åˆ¶ï¼Œè°ƒæ•´ä¸ºæœ€è¿‘30å¤©")
                start_time = thirty_days_ago.strftime("%Y-%m-%d")

            all_long_short_ratios = []
            downloaded_count = 0
            failed_count = 0

            for i, symbol in enumerate(symbols):
                try:
                    logger.debug(f"è·å– {symbol} å¤šç©ºæ¯”ä¾‹ ({i + 1}/{len(symbols)})")

                    # é¢‘ç‡é™åˆ¶
                    if request_delay > 0:
                        time.sleep(request_delay)

                    long_short_ratios = self.download_long_short_ratio(
                        symbol=symbol,
                        period=period,
                        ratio_type=ratio_type,
                        start_time=start_time,
                        end_time=end_time,
                        limit=500,
                    )

                    if long_short_ratios:
                        all_long_short_ratios.extend(long_short_ratios)
                        downloaded_count += 1
                        logger.debug(f"âœ… {symbol}: {len(long_short_ratios)} æ¡è®°å½•")
                    else:
                        logger.debug(f"âš ï¸ {symbol}: æ— æ•°æ®")

                except Exception as e:
                    failed_count += 1
                    logger.warning(f"âŒ {symbol}: {e}")
                    self._record_failed_download(
                        symbol,
                        str(e),
                        {
                            "data_type": "long_short_ratio",
                            "ratio_type": ratio_type,
                            "start_time": start_time,
                            "end_time": end_time,
                        },
                    )

            # æ‰¹é‡å­˜å‚¨
            if all_long_short_ratios and self.db:
                await self.db.store_long_short_ratio(all_long_short_ratios)
                logger.info(f"âœ… å­˜å‚¨äº† {len(all_long_short_ratios)} æ¡å¤šç©ºæ¯”ä¾‹è®°å½•")

            logger.info(f"ğŸ“Š å¤šç©ºæ¯”ä¾‹æ•°æ®ä¸‹è½½å®Œæˆ: æˆåŠŸ {downloaded_count}/{len(symbols)}ï¼Œå¤±è´¥ {failed_count}")

        except Exception as e:
            logger.error(f"æ‰¹é‡ä¸‹è½½å¤šç©ºæ¯”ä¾‹å¤±è´¥: {e}")
            raise MarketDataFetchError(f"æ‰¹é‡ä¸‹è½½å¤šç©ºæ¯”ä¾‹å¤±è´¥: {e}") from e

    def download_funding_rate(
        self,
        symbol: str,
        start_time: str | None = None,
        end_time: str | None = None,
        limit: int = 100,
    ) -> List[FundingRate]:
        """ä¸‹è½½å•ä¸ªäº¤æ˜“å¯¹çš„èµ„é‡‘è´¹ç‡æ•°æ®"""
        try:

            def request_func():
                params = {"symbol": symbol, "limit": limit}
                if start_time:
                    params["startTime"] = self._date_to_timestamp_start(start_time)
                if end_time:
                    params["endTime"] = self._date_to_timestamp_end(end_time)
                return self.client.futures_funding_rate(**params)

            data = self._handle_request_with_retry(request_func)

            if not data:
                return []

            return [FundingRate.from_binance_response(item) for item in data]

        except Exception as e:
            logger.error(f"è·å–èµ„é‡‘è´¹ç‡å¤±è´¥ {symbol}: {e}")
            raise MarketDataFetchError(f"è·å–èµ„é‡‘è´¹ç‡å¤±è´¥: {e}") from e

    def download_open_interest(
        self,
        symbol: str,
        period: str = "5m",
        start_time: str | None = None,
        end_time: str | None = None,
        limit: int = 500,
    ) -> List[OpenInterest]:
        """ä¸‹è½½å•ä¸ªäº¤æ˜“å¯¹çš„æŒä»“é‡æ•°æ®"""
        try:

            def request_func():
                params = {"symbol": symbol, "period": period, "limit": min(limit, 500)}
                if start_time:
                    params["startTime"] = self._date_to_timestamp_start(start_time)
                if end_time:
                    params["endTime"] = self._date_to_timestamp_end(end_time)
                return self.client.futures_open_interest_hist(**params)

            data = self._handle_request_with_retry(request_func)

            if not data:
                return []

            return [OpenInterest.from_binance_response(item) for item in data]

        except Exception as e:
            logger.error(f"è·å–æŒä»“é‡å¤±è´¥ {symbol}: {e}")
            raise MarketDataFetchError(f"è·å–æŒä»“é‡å¤±è´¥: {e}") from e

    def download_long_short_ratio(
        self,
        symbol: str,
        period: str = "5m",
        ratio_type: str = "account",
        start_time: str | None = None,
        end_time: str | None = None,
        limit: int = 500,
    ) -> List[LongShortRatio]:
        """ä¸‹è½½å•ä¸ªäº¤æ˜“å¯¹çš„å¤šç©ºæ¯”ä¾‹æ•°æ®"""
        try:

            def request_func():
                params = {"symbol": symbol, "period": period, "limit": min(limit, 500)}
                if start_time:
                    params["startTime"] = self._date_to_timestamp_start(start_time)
                if end_time:
                    params["endTime"] = self._date_to_timestamp_end(end_time)

                # æ ¹æ®ratio_typeé€‰æ‹©APIç«¯ç‚¹
                if ratio_type == "account":
                    return self.client.futures_top_longshort_account_ratio(**params)
                elif ratio_type == "position":
                    return self.client.futures_top_longshort_position_ratio(**params)
                elif ratio_type == "global":
                    return self.client.futures_global_longshort_ratio(**params)
                elif ratio_type == "taker":
                    return self.client.futures_taker_longshort_ratio(**params)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„ratio_type: {ratio_type}")

            data = self._handle_request_with_retry(request_func)

            if not data:
                return []

            return [LongShortRatio.from_binance_response(item, ratio_type) for item in data]

        except Exception as e:
            logger.error(f"è·å–å¤šç©ºæ¯”ä¾‹å¤±è´¥ {symbol}: {e}")
            raise MarketDataFetchError(f"è·å–å¤šç©ºæ¯”ä¾‹å¤±è´¥: {e}") from e

    def _date_to_timestamp_start(self, date: str) -> str:
        """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºå½“å¤©å¼€å§‹çš„æ—¶é—´æˆ³"""
        timestamp = int(datetime.strptime(f"{date} 00:00:00", "%Y-%m-%d %H:%M:%S").timestamp() * 1000)
        return str(timestamp)

    def _date_to_timestamp_end(self, date: str) -> str:
        """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºå½“å¤©ç»“æŸçš„æ—¶é—´æˆ³"""
        timestamp = int(datetime.strptime(f"{date} 23:59:59", "%Y-%m-%d %H:%M:%S").timestamp() * 1000)
        return str(timestamp)

    def download(self, *args, **kwargs):
        """å®ç°åŸºç±»çš„æŠ½è±¡æ–¹æ³•"""
        # è¿™é‡Œå¯ä»¥æ ¹æ®å‚æ•°å†³å®šè°ƒç”¨å“ªä¸ªå…·ä½“çš„ä¸‹è½½æ–¹æ³•
        if "funding_rate" in kwargs:
            return self.download_funding_rate_batch(*args, **kwargs)
        elif "open_interest" in kwargs:
            return self.download_open_interest_batch(*args, **kwargs)
        elif "long_short_ratio" in kwargs:
            return self.download_long_short_ratio_batch(*args, **kwargs)
        else:
            raise ValueError("è¯·æŒ‡å®šè¦ä¸‹è½½çš„æ•°æ®ç±»å‹")
