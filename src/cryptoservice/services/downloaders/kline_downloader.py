"""Kçº¿æ•°æ®ä¸‹è½½å™¨ã€‚.

ä¸“é—¨å¤„ç†Kçº¿æ•°æ®çš„ä¸‹è½½ï¼ŒåŒ…æ‹¬ç°è´§å’ŒæœŸè´§Kçº¿æ•°æ®ã€‚
"""

import logging
from datetime import datetime
from pathlib import Path

from cryptoservice.config import RetryConfig
from cryptoservice.exceptions import InvalidSymbolError, MarketDataFetchError
from cryptoservice.models import (
    Freq,
    HistoricalKlinesType,
    IntegrityReport,
    PerpetualMarketTicker,
)
from cryptoservice.storage import AsyncMarketDB

from .base_downloader import BaseDownloader

logger = logging.getLogger(__name__)


class KlineDownloader(BaseDownloader):
    """Kçº¿æ•°æ®ä¸‹è½½å™¨."""

    def __init__(self, client, request_delay: float = 0.5):
        """åˆå§‹åŒ–Kçº¿æ•°æ®ä¸‹è½½å™¨.

        Args:
            client: API å®¢æˆ·ç«¯å®ä¾‹.
            request_delay: è¯·æ±‚ä¹‹é—´çš„åŸºç¡€å»¶è¿Ÿï¼ˆç§’ï¼‰.
        """
        super().__init__(client, request_delay)
        self.db: AsyncMarketDB | None = None

    def download_single_symbol(
        self,
        symbol: str,
        start_ts: str,
        end_ts: str,
        interval: Freq,
        klines_type: HistoricalKlinesType = HistoricalKlinesType.FUTURES,
        retry_config: RetryConfig | None = None,
    ) -> list[PerpetualMarketTicker]:
        """ä¸‹è½½å•ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®."""
        try:
            logger.debug(f"ä¸‹è½½ {symbol} çš„Kçº¿æ•°æ®: {start_ts} - {end_ts}")

            def request_func():
                return self.client.get_historical_klines_generator(
                    symbol=symbol,
                    interval=interval.value,
                    start_str=start_ts,
                    end_str=end_ts,
                    limit=1500,
                    klines_type=HistoricalKlinesType.to_binance(klines_type),
                )

            klines = self._handle_request_with_retry(request_func, retry_config=retry_config)
            data = list(klines)

            if not data:
                logger.debug(f"äº¤æ˜“å¯¹ {symbol} åœ¨æŒ‡å®šæ—¶é—´æ®µå†…æ— æ•°æ®")
                return []

            # æ•°æ®è´¨é‡æ£€æŸ¥
            valid_data = self._validate_kline_data(data, symbol)

            # è½¬æ¢ä¸ºå¯¹è±¡
            result = [
                PerpetualMarketTicker(
                    symbol=symbol,
                    open_time=kline[0],
                    raw_data=kline,
                )
                for kline in valid_data
            ]

            logger.debug(f"æˆåŠŸä¸‹è½½ {symbol}: {len(result)} æ¡è®°å½•")
            return result

        except InvalidSymbolError:
            logger.warning(f"âš ï¸ æ— æ•ˆäº¤æ˜“å¯¹: {symbol}")
            raise
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½ {symbol} å¤±è´¥: {e}")
            self._record_failed_download(
                symbol,
                str(e),
                {
                    "start_ts": start_ts,
                    "end_ts": end_ts,
                    "interval": interval.value,
                },
            )
            raise MarketDataFetchError(f"ä¸‹è½½äº¤æ˜“å¯¹ {symbol} æ•°æ®å¤±è´¥: {e}") from e

    async def download_multiple_symbols(
        self,
        symbols: list[str],
        start_time: str,
        end_time: str,
        interval: Freq,
        db_path: Path,
        max_workers: int = 5,
        retry_config: RetryConfig | None = None,
    ) -> IntegrityReport:
        """æ‰¹é‡ä¸‹è½½å¤šä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®."""
        from concurrent.futures import ThreadPoolExecutor, as_completed

        # åˆå§‹åŒ–æ•°æ®åº“
        if self.db is None:
            self.db = AsyncMarketDB(str(db_path))

        # è½¬æ¢æ—¶é—´æ ¼å¼
        start_ts = self._date_to_timestamp_start(start_time)
        end_ts = self._date_to_timestamp_end(end_time)

        successful_symbols = []
        failed_symbols = []
        missing_periods = []

        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(symbols)} ä¸ªäº¤æ˜“å¯¹çš„Kçº¿æ•°æ®")

        async def process_symbol(symbol: str):
            """å¤„ç†å•ä¸ªäº¤æ˜“å¯¹."""
            try:
                data = self.download_single_symbol(
                    symbol=symbol,
                    start_ts=start_ts,
                    end_ts=end_ts,
                    interval=interval,
                    retry_config=retry_config,
                )

                if data and self.db:
                    await self.db.store_data(data, interval)
                    successful_symbols.append(symbol)
                    logger.debug(f"âœ… {symbol}: {len(data)} æ¡è®°å½•")
                else:
                    logger.debug(f"âš ï¸ {symbol}: æ— æ•°æ®")
                    missing_periods.append(
                        {
                            "symbol": symbol,
                            "period": f"{start_time} - {end_time}",
                            "reason": "no_data",
                        }
                    )

            except Exception as e:
                logger.error(f"âŒ {symbol} å¤±è´¥: {e}")
                failed_symbols.append(symbol)
                missing_periods.append(
                    {
                        "symbol": symbol,
                        "period": f"{start_time} - {end_time}",
                        "reason": str(e),
                    }
                )

        # å¹¶è¡Œä¸‹è½½
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(process_symbol, symbol) for symbol in symbols]
            for future in as_completed(futures):
                try:
                    await future.result()
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†å¼‚å¸¸: {e}")

        # ç”ŸæˆæŠ¥å‘Š
        logger.info(f"ğŸ“Š ä¸‹è½½å®Œæˆ: æˆåŠŸ {len(successful_symbols)}/{len(symbols)}")

        return IntegrityReport(
            total_symbols=len(symbols),
            successful_symbols=len(successful_symbols),
            failed_symbols=failed_symbols,
            missing_periods=missing_periods,
            data_quality_score=len(successful_symbols) / len(symbols) if symbols else 0,
            recommendations=self._generate_recommendations(successful_symbols, failed_symbols),
        )

    def _validate_kline_data(self, data: list, symbol: str) -> list:
        """éªŒè¯Kçº¿æ•°æ®è´¨é‡."""
        if not data:
            return data

        valid_data = []
        issues = []

        for i, kline in enumerate(data):
            try:
                # æ£€æŸ¥æ•°æ®ç»“æ„
                if len(kline) < 8:
                    issues.append(f"è®°å½•{i}: æ•°æ®å­—æ®µä¸è¶³")
                    continue

                # æ£€æŸ¥ä»·æ ¼æ•°æ®æœ‰æ•ˆæ€§
                open_price = float(kline[1])
                high_price = float(kline[2])
                low_price = float(kline[3])
                close_price = float(kline[4])
                volume = float(kline[5])

                # åŸºç¡€é€»è¾‘æ£€æŸ¥
                if high_price < max(open_price, close_price, low_price):
                    issues.append(f"è®°å½•{i}: æœ€é«˜ä»·å¼‚å¸¸")
                    continue

                if low_price > min(open_price, close_price, high_price):
                    issues.append(f"è®°å½•{i}: æœ€ä½ä»·å¼‚å¸¸")
                    continue

                if volume < 0:
                    issues.append(f"è®°å½•{i}: æˆäº¤é‡ä¸ºè´Ÿ")
                    continue

                valid_data.append(kline)

            except (ValueError, IndexError) as e:
                issues.append(f"è®°å½•{i}: æ•°æ®æ ¼å¼é”™è¯¯ - {e}")
                continue

        if issues:
            issue_count = len(issues)
            total_count = len(data)
            if issue_count > total_count * 0.1:  # è¶…è¿‡10%çš„æ•°æ®æœ‰é—®é¢˜
                logger.warning(f"âš ï¸ {symbol} æ•°æ®è´¨é‡é—®é¢˜: {issue_count}/{total_count} æ¡è®°å½•å¼‚å¸¸")

        return valid_data

    def _date_to_timestamp_start(self, date: str) -> str:
        """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºå½“å¤©å¼€å§‹çš„æ—¶é—´æˆ³."""
        timestamp = int(datetime.strptime(f"{date} 00:00:00", "%Y-%m-%d %H:%M:%S").timestamp() * 1000)
        return str(timestamp)

    def _date_to_timestamp_end(self, date: str) -> str:
        """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºå½“å¤©ç»“æŸçš„æ—¶é—´æˆ³."""
        timestamp = int(datetime.strptime(f"{date} 23:59:59", "%Y-%m-%d %H:%M:%S").timestamp() * 1000)
        return str(timestamp)

    def _generate_recommendations(self, successful_symbols: list[str], failed_symbols: list[str]) -> list[str]:
        """ç”Ÿæˆå»ºè®®."""
        recommendations = []
        success_rate = len(successful_symbols) / (len(successful_symbols) + len(failed_symbols))

        if success_rate < 0.5:
            recommendations.append("ğŸš¨ æ•°æ®è´¨é‡ä¸¥é‡ä¸è¶³ï¼Œå»ºè®®é‡æ–°ä¸‹è½½")
        elif success_rate < 0.8:
            recommendations.append("âš ï¸ æ•°æ®è´¨é‡ä¸€èˆ¬ï¼Œå»ºè®®æ£€æŸ¥å¤±è´¥çš„äº¤æ˜“å¯¹")
        else:
            recommendations.append("âœ… æ•°æ®è´¨é‡è‰¯å¥½")

        if failed_symbols:
            recommendations.append(f"ğŸ“ {len(failed_symbols)}ä¸ªäº¤æ˜“å¯¹ä¸‹è½½å¤±è´¥ï¼Œå»ºè®®å•ç‹¬é‡è¯•")

        return recommendations

    def download(self, *args, **kwargs):
        """å®ç°åŸºç±»çš„æŠ½è±¡æ–¹æ³•."""
        return self.download_multiple_symbols(*args, **kwargs)
